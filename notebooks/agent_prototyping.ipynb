{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAER Agent Prototyping Workbench\n",
    "\n",
    "This notebook provides an interactive environment for developing and testing clinical shadow agents.\n",
    "\n",
    "## Contents\n",
    "1. Setup & Imports\n",
    "2. Running Simulations\n",
    "3. Creating MetricsSummary\n",
    "4. Testing Agents\n",
    "5. Exploring Insights\n",
    "6. Custom Rule Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path if needed\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root / 'src') not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAER simulation imports\n",
    "from faer.core.scenario import FullScenario\n",
    "from faer.model.full_model import run_full_simulation\n",
    "from faer.experiment.runner import multiple_replications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent imports\n",
    "from faer.agents import (\n",
    "    HeuristicShadowAgent,\n",
    "    AgentOrchestrator,\n",
    "    OrchestratorConfig,\n",
    "    MetricsSummary,\n",
    "    ClinicalThreshold,\n",
    "    Severity,\n",
    "    InsightCategory,\n",
    "    NHS_THRESHOLDS,\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running Simulations\n",
    "\n",
    "Let's run some simulations to generate data for agent testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline \"healthy\" scenario\n",
    "healthy_scenario = FullScenario(\n",
    "    run_length=480.0,      # 8 hours\n",
    "    warm_up=60.0,          # 1 hour warm-up\n",
    "    n_triage=2,\n",
    "    n_ed_bays=8,\n",
    "    arrival_rate=6.0,      # 6 patients/hour\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Healthy scenario: {healthy_scenario.n_ed_bays} ED bays, {healthy_scenario.arrival_rate}/hr arrivals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"stressed\" scenario\n",
    "stressed_scenario = FullScenario(\n",
    "    run_length=480.0,\n",
    "    warm_up=60.0,\n",
    "    n_triage=1,            # Understaffed\n",
    "    n_ed_bays=4,           # Limited bays\n",
    "    arrival_rate=10.0,     # High demand\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Stressed scenario: {stressed_scenario.n_ed_bays} ED bays, {stressed_scenario.arrival_rate}/hr arrivals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple replications\n",
    "print(\"Running healthy scenario (5 reps)...\")\n",
    "healthy_results = multiple_replications(healthy_scenario, n_reps=5)\n",
    "print(f\"  Arrivals: {np.mean(healthy_results['arrivals']):.1f}\")\n",
    "print(f\"  Mean treatment wait: {np.mean(healthy_results['mean_treatment_wait']):.1f} min\")\n",
    "\n",
    "print(\"\\nRunning stressed scenario (5 reps)...\")\n",
    "stressed_results = multiple_replications(stressed_scenario, n_reps=5)\n",
    "print(f\"  Arrivals: {np.mean(stressed_results['arrivals']):.1f}\")\n",
    "print(f\"  Mean treatment wait: {np.mean(stressed_results['mean_treatment_wait']):.1f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating MetricsSummary\n",
    "\n",
    "Convert raw results to the standardized MetricsSummary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to MetricsSummary\n",
    "healthy_metrics = MetricsSummary.from_run_results(healthy_results, \"Healthy Baseline\")\n",
    "stressed_metrics = MetricsSummary.from_run_results(stressed_results, \"Stressed System\")\n",
    "\n",
    "print(\"Healthy Metrics:\")\n",
    "print(f\"  Arrivals: {healthy_metrics.arrivals:.0f}\")\n",
    "print(f\"  Mean treatment wait: {healthy_metrics.mean_treatment_wait:.1f} min\")\n",
    "print(f\"  P95 treatment wait: {healthy_metrics.p95_treatment_wait:.1f} min\")\n",
    "print(f\"  ED utilization: {healthy_metrics.util_ed_bays:.1%}\")\n",
    "print(f\"  P(delay): {healthy_metrics.p_delay:.1%}\")\n",
    "\n",
    "print(\"\\nStressed Metrics:\")\n",
    "print(f\"  Arrivals: {stressed_metrics.arrivals:.0f}\")\n",
    "print(f\"  Mean treatment wait: {stressed_metrics.mean_treatment_wait:.1f} min\")\n",
    "print(f\"  P95 treatment wait: {stressed_metrics.p95_treatment_wait:.1f} min\")\n",
    "print(f\"  ED utilization: {stressed_metrics.util_ed_bays:.1%}\")\n",
    "print(f\"  P(delay): {stressed_metrics.p_delay:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing Agents\n",
    "\n",
    "Run the HeuristicShadowAgent against our scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "agent = HeuristicShadowAgent()\n",
    "\n",
    "print(f\"Agent: {agent.name}\")\n",
    "print(f\"Description: {agent.description}\")\n",
    "print(f\"Health check: {agent.health_check()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze healthy scenario\n",
    "healthy_insights = agent.analyze(healthy_metrics)\n",
    "\n",
    "print(f\"Healthy scenario insights: {len(healthy_insights)}\")\n",
    "for insight in healthy_insights:\n",
    "    print(f\"  [{insight.severity.value}] {insight.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze stressed scenario\n",
    "stressed_insights = agent.analyze(stressed_metrics)\n",
    "\n",
    "print(f\"Stressed scenario insights: {len(stressed_insights)}\")\n",
    "for insight in stressed_insights:\n",
    "    print(f\"  [{insight.severity.value}] {insight.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploring Insights\n",
    "\n",
    "Dive deeper into the insights generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed view of each insight\n",
    "for i, insight in enumerate(stressed_insights, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"INSIGHT {i}: {insight.title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Severity: {insight.severity.value}\")\n",
    "    print(f\"Category: {insight.category.value}\")\n",
    "    print(f\"\\nMessage:\\n{insight.message}\")\n",
    "    print(f\"\\nEvidence:\")\n",
    "    for k, v in insight.evidence.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"\\nRecommendation:\\n{insight.recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the orchestrator\n",
    "orchestrator = AgentOrchestrator()\n",
    "orchestrator.register(agent)\n",
    "\n",
    "result = orchestrator.run_all(stressed_metrics)\n",
    "\n",
    "print(\"Orchestrator Summary:\")\n",
    "pprint(result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by severity\n",
    "critical = result.get_critical_insights()\n",
    "high_and_critical = result.get_high_and_critical()\n",
    "\n",
    "print(f\"Critical insights: {len(critical)}\")\n",
    "print(f\"High + Critical insights: {len(high_and_critical)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Rule Development\n",
    "\n",
    "Create and test custom clinical threshold rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View existing NHS thresholds\n",
    "print(\"NHS Thresholds:\")\n",
    "for rule in NHS_THRESHOLDS:\n",
    "    print(f\"  {rule.title}: {rule.metric} {rule.operator} {rule.threshold} -> {rule.severity.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom thresholds\n",
    "custom_thresholds = [\n",
    "    ClinicalThreshold(\n",
    "        metric=\"p95_treatment_wait\",\n",
    "        threshold=120.0,  # Stricter 2-hour target\n",
    "        operator=\"gt\",\n",
    "        severity=Severity.HIGH,\n",
    "        category=InsightCategory.WAIT_TIME,\n",
    "        title=\"2-Hour Wait Standard Exceeded\",\n",
    "        message_template=(\n",
    "            \"P95 treatment wait of {value:.0f} minutes exceeds our 2-hour target. \"\n",
    "            \"This is stricter than NHS standards but aligns with our quality goals.\"\n",
    "        ),\n",
    "        recommendation=\"Review patient flow and consider additional resources.\",\n",
    "    ),\n",
    "    ClinicalThreshold(\n",
    "        metric=\"util_ed_bays\",\n",
    "        threshold=0.70,  # Earlier warning\n",
    "        operator=\"gt\",\n",
    "        severity=Severity.MEDIUM,\n",
    "        category=InsightCategory.CAPACITY,\n",
    "        title=\"ED Capacity Warning\",\n",
    "        message_template=(\n",
    "            \"ED bay utilization at {value:.0%}. While not critical, \"\n",
    "            \"this is approaching levels where congestion may develop.\"\n",
    "        ),\n",
    "        recommendation=\"Monitor closely. Consider proactive discharge planning.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Custom thresholds created:\")\n",
    "for rule in custom_thresholds:\n",
    "    print(f\"  {rule.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test custom agent\n",
    "custom_agent = HeuristicShadowAgent(thresholds=custom_thresholds)\n",
    "\n",
    "custom_insights = custom_agent.analyze(healthy_metrics)\n",
    "\n",
    "print(f\"Custom agent insights on healthy scenario: {len(custom_insights)}\")\n",
    "for insight in custom_insights:\n",
    "    print(f\"  [{insight.severity.value}] {insight.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine NHS + custom thresholds\n",
    "combined_agent = HeuristicShadowAgent(thresholds=NHS_THRESHOLDS + custom_thresholds)\n",
    "\n",
    "combined_insights = combined_agent.analyze(stressed_metrics)\n",
    "\n",
    "print(f\"Combined agent insights on stressed scenario: {len(combined_insights)}\")\n",
    "for insight in combined_insights:\n",
    "    print(f\"  [{insight.severity.value}] {insight.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manual Metrics Testing\n",
    "\n",
    "Create synthetic metrics to test specific edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scenario with specific metrics to trigger compound rules\n",
    "compound_test_metrics = MetricsSummary(\n",
    "    scenario_name=\"compound_test\",\n",
    "    run_timestamp=\"2026-01-10T12:00:00\",\n",
    "    n_replications=1,\n",
    "    arrivals=300,\n",
    "    arrivals_by_priority={\"P1\": 30, \"P2\": 90, \"P3\": 120, \"P4\": 60},  # 10% P1\n",
    "    arrivals_by_mode={\"ambulance\": 200, \"helicopter\": 20, \"walk_in\": 80},\n",
    "    mean_triage_wait=15.0,\n",
    "    mean_treatment_wait=90.0,  # High - should trigger compound with P1\n",
    "    p95_treatment_wait=180.0,  # Under 4-hour threshold\n",
    "    mean_system_time=200.0,\n",
    "    p95_system_time=350.0,\n",
    "    p_delay=0.40,\n",
    "    util_triage=0.30,  # Low triage but high treatment wait\n",
    "    util_ed_bays=0.80,\n",
    "    util_itu=0.88,  # High ITU\n",
    "    util_ward=0.75,\n",
    "    util_theatre=0.75,  # High theatre - should trigger compound with ITU\n",
    "    itu_admissions=25,\n",
    "    mean_itu_wait=45.0,\n",
    "    ward_admissions=80,\n",
    "    mean_ward_wait=30.0,\n",
    "    theatre_admissions=15,\n",
    "    mean_theatre_wait=60.0,\n",
    "    mean_boarding_time=35.0,\n",
    "    p_boarding=0.20,\n",
    "    mean_handover_delay=25.0,\n",
    "    max_handover_delay=60.0,\n",
    ")\n",
    "\n",
    "# Analyze\n",
    "compound_insights = agent.analyze(compound_test_metrics)\n",
    "\n",
    "print(\"Compound rule testing:\")\n",
    "for insight in compound_insights:\n",
    "    print(f\"  [{insight.severity.value}] {insight.title}\")\n",
    "    if insight.category == InsightCategory.COMPOUND_RISK or insight.title.startswith(\"High Acuity\"):\n",
    "        print(f\"    -> This is a compound rule!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Ideas for extending the agent layer:\n",
    "\n",
    "1. **LLM Integration**: Replace heuristic logic with LLM analysis\n",
    "2. **Capacity Advisor Agent**: Recommend specific capacity changes\n",
    "3. **Scenario Comparator**: Compare metrics across scenarios\n",
    "4. **Historical Memory**: Track patterns across multiple runs\n",
    "5. **Custom Visualization**: Create dashboards for insights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
